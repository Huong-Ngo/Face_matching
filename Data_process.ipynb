{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train_arcface import train_arcface\n",
    "from src.utils.model import get_triplet_model, freeze_layer\n",
    "from src.model.arcface import KSubArcFace, ArcFace_org\n",
    "import torch\n",
    "from train_triplet import train_triplet\n",
    "from train_arc_triplet import train_arc_triplet\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT_PATH = 'weight/backbone_r100_glint360k.pt'\n",
    "TRAIN_PATH = \"triplet_train.txt\"\n",
    "TEST_PATH = \"triplet_valid.txt\"\n",
    "EPOCHS = 10\n",
    "BATCH__SIZE = 16\n",
    "\n",
    "# FINETUNE_PATH = 'weight/model_finetune_arcface_org_best.pth'\n",
    "# ARCFACE_PATH = 'weight/arcface_org_weight_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 2800 is out of bounds for dimension 1 with size 670",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m arcface \u001b[39m=\u001b[39m ArcFace_org(in_features \u001b[39m=\u001b[39m \u001b[39m512\u001b[39m, out_features \u001b[39m=\u001b[39m \u001b[39m670\u001b[39m, s \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m, m \u001b[39m=\u001b[39m \u001b[39m1.\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# arcface.load_state_dict(torch.load(ARCFACE_PATH, map_location = 'cpu')['model_state_dict'])\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m train_arc_triplet(model, arcface, TRAIN_PATH, TEST_PATH, EPOCHS, BATCH__SIZE, checkpoint_path\u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mweight_triplet_arc\u001b[39;49m\u001b[39m'\u001b[39;49m )\n",
      "File \u001b[1;32md:\\Projects\\FaceMatching\\train_arc_triplet.py:182\u001b[0m, in \u001b[0;36mtrain_arc_triplet\u001b[1;34m(model, arcface, train_path, test_path, epochs, batch_size, device, checkpoint_path)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[39m# validation(model,testloader, test_criterion)\u001b[39;00m\n\u001b[0;32m    179\u001b[0m \n\u001b[0;32m    180\u001b[0m \u001b[39m# train and validate after each epoch (or specify it to be after a desired number)\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m,epochs\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m--> 182\u001b[0m     train_one_epoch(model, arcface, device, trainloader, optimizer, criterion, epoch)\n",
      "File \u001b[1;32md:\\Projects\\FaceMatching\\train_arc_triplet.py:131\u001b[0m, in \u001b[0;36mtrain_arc_triplet.<locals>.train_one_epoch\u001b[1;34m(model, arcface, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[0;32m    129\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m    130\u001b[0m feature_anchor, feature_positive, feature_negative \u001b[39m=\u001b[39m model(anchor, positive, negative) \u001b[39m# get the embeddings\u001b[39;00m\n\u001b[1;32m--> 131\u001b[0m out_anchor, out_positive, out_negative \u001b[39m=\u001b[39m arcface(feature_anchor, a_label), arcface(feature_positive, p_label), arcface(feature_negative, n_label)\n\u001b[0;32m    132\u001b[0m loss \u001b[39m=\u001b[39m criterion(out_anchor,out_positive,out_negative,a_label,p_label,n_label) \u001b[39m# compute the loss\u001b[39;00m\n\u001b[0;32m    133\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Projects\\FaceMatching\\src\\model\\arcface.py:356\u001b[0m, in \u001b[0;36mArcFace_org.forward\u001b[1;34m(self, input, label)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[39m# --------------------------- convert label to one-hot ---------------------------\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \u001b[39m# one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\u001b[39;00m\n\u001b[0;32m    355\u001b[0m one_hot \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mzeros(cosine\u001b[39m.\u001b[39msize(), device\u001b[39m=\u001b[39m\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m--> 356\u001b[0m one_hot\u001b[39m.\u001b[39;49mscatter_(\u001b[39m1\u001b[39;49m, label\u001b[39m.\u001b[39;49mview(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mlong(), \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    357\u001b[0m \u001b[39m# -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\u001b[39;00m\n\u001b[0;32m    358\u001b[0m output \u001b[39m=\u001b[39m (one_hot \u001b[39m*\u001b[39m phi) \u001b[39m+\u001b[39m ((\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m one_hot) \u001b[39m*\u001b[39m cosine)  \u001b[39m# you can use torch.where if your torch.__version__ is 0.4\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index 2800 is out of bounds for dimension 1 with size 670"
     ]
    }
   ],
   "source": [
    "model = get_triplet_model(weight_path= WEIGHT_PATH)\n",
    "# model.backbone.load_state_dict(torch.load(FINETUNE_PATH, map_location = 'cpu')['model_state_dict'])\n",
    "\n",
    "arcface = ArcFace_org(in_features = 512, out_features = 670, s = 30, m = 1.)\n",
    "# arcface.load_state_dict(torch.load(ARCFACE_PATH, map_location = 'cpu')['model_state_dict'])\n",
    "\n",
    "\n",
    "train_arc_triplet(model, arcface, TRAIN_PATH, TEST_PATH, EPOCHS, BATCH__SIZE, checkpoint_path= 'weight_triplet_arc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,p,n,_,_,_ = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = get_triplet_model(weight_path= WEIGHT_PATH)\n",
    "# freeze_layer(model, ['253', '254'])\n",
    "# train_triplet(model, TRAIN_PATH, TEST_PATH, EPOCHS, BATCH__SIZE, roc_fig_path='result/finetune_triplet_loss.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
